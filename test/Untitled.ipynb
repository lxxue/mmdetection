{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from mmcv.runner import load_checkpoint, get_dist_info\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "\n",
    "from mmdet.apis import init_dist\n",
    "from mmdet.core import results2json, coco_eval, wrap_fp16_model\n",
    "from mmdet.datasets import build_dataloader, build_dataset\n",
    "from mmdet.models import build_detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_gpu_test(model, data_loader, show=False):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    dataset = data_loader.dataset\n",
    "    prog_bar = mmcv.ProgressBar(len(dataset))\n",
    "    for i, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            result = model(return_loss=False, rescale=not show, **data)\n",
    "        results.append(result)\n",
    "\n",
    "        if show:\n",
    "            model.module.show_result(data, result, dataset.img_norm_cfg)\n",
    "\n",
    "        batch_size = data['img'][0].size(0)\n",
    "        for _ in range(batch_size):\n",
    "            prog_bar.update()\n",
    "    return results\n",
    "\n",
    "\n",
    "def multi_gpu_test(model, data_loader, tmpdir=None):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    dataset = data_loader.dataset\n",
    "    rank, world_size = get_dist_info()\n",
    "    if rank == 0:\n",
    "        prog_bar = mmcv.ProgressBar(len(dataset))\n",
    "    for i, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            result = model(return_loss=False, rescale=True, **data)\n",
    "        results.append(result)\n",
    "\n",
    "        if rank == 0:\n",
    "            batch_size = data['img'][0].size(0)\n",
    "            for _ in range(batch_size * world_size):\n",
    "                prog_bar.update()\n",
    "\n",
    "    # collect results from all ranks\n",
    "    results = collect_results(results, len(dataset), tmpdir)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def collect_results(result_part, size, tmpdir=None):\n",
    "    rank, world_size = get_dist_info()\n",
    "    # create a tmp dir if it is not specified\n",
    "    if tmpdir is None:\n",
    "        MAX_LEN = 512\n",
    "        # 32 is whitespace\n",
    "        dir_tensor = torch.full((MAX_LEN, ),\n",
    "                                32,\n",
    "                                dtype=torch.uint8,\n",
    "                                device='cuda')\n",
    "        if rank == 0:\n",
    "            tmpdir = tempfile.mkdtemp()\n",
    "            tmpdir = torch.tensor(\n",
    "                bytearray(tmpdir.encode()), dtype=torch.uint8, device='cuda')\n",
    "            dir_tensor[:len(tmpdir)] = tmpdir\n",
    "        dist.broadcast(dir_tensor, 0)\n",
    "        tmpdir = dir_tensor.cpu().numpy().tobytes().decode().rstrip()\n",
    "    else:\n",
    "        mmcv.mkdir_or_exist(tmpdir)\n",
    "    # dump the part result to the dir\n",
    "    mmcv.dump(result_part, osp.join(tmpdir, 'part_{}.pkl'.format(rank)))\n",
    "    dist.barrier()\n",
    "    # collect all parts\n",
    "    if rank != 0:\n",
    "        return None\n",
    "    else:\n",
    "        # load results of all parts from tmp dir\n",
    "        part_list = []\n",
    "        for i in range(world_size):\n",
    "            part_file = osp.join(tmpdir, 'part_{}.pkl'.format(i))\n",
    "            part_list.append(mmcv.load(part_file))\n",
    "        # sort the results\n",
    "        ordered_results = []\n",
    "        for res in zip(*part_list):\n",
    "            ordered_results.extend(list(res))\n",
    "        # the dataloader may pad some samples\n",
    "        ordered_results = ordered_results[:size]\n",
    "        # remove tmp dir\n",
    "        shutil.rmtree(tmpdir)\n",
    "        return ordered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
